'''
This function processes a RDS enhanced monitoring DATA_MESSAGE, coming from CloudWatch Logs,
and sends the data to a specified Graphite instance via the Carbon protocol.

This is based on code to send these stats to DataDog, via:
  https://github.com/DataDog/dd-aws-lambda-functions
'''

import gzip
import json
import re
from StringIO import StringIO
from base64 import b64decode
import time
import graphitesend
import logging

# specify Graphite host
CARBON_SERVER = 'ip-of-graphite-host'
CARBON_PORT = 2003
# This is what you want to prefix the data generated by this script with
CARBON_NAMESPACE = "lambda.rdsenhanced"

# Main logger log level - controls graphitesend
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)

# Start logging - create our own distinct logger name, to not interfere with graphitesend's logger.
lambdalogger = logging.getLogger("LogsToGraphite")
#lambdalogger.setLevel(logging.INFO)
lambdalogger.setLevel(logging.DEBUG)
    
lambdalogger.info('Lambda function initialized, ready to send metrics.')

def _process_rds_enhanced_monitoring_message(ts, message, account, region, combined_events):
    instance_id = message["instanceID"]
    host_id = message["instanceResourceID"]
    tags = [
        'dbinstanceidentifier:%s' % instance_id,
        'aws_account:%s' % account,
        'engine:%s' % message["engine"],
    ]

    # metrics generation

    # uptime: "54 days, 1:53:04" to be converted into seconds
    uptime = 0
    uptime_msg = re.split(' days?, ', message["uptime"])  # edge case "1 day 1:53:04"
    if len(uptime_msg) == 2:
        uptime += 24 * 3600 * int(uptime_msg[0])
    uptime_day = uptime_msg[-1].split(':')
    uptime += 3600 * int(uptime_day[0])
    uptime += 60 * int(uptime_day[1])
    uptime += int(uptime_day[2])
    stats.add(instance_id,
        'uptime', uptime, timestamp=ts, tags=tags, host=host_id
    )

    stats.add(instance_id,
        'virtual_cpus', message["numVCPUs"], timestamp=ts, tags=tags, host=host_id
    )

    stats.add(instance_id,
        'load.1', message["loadAverageMinute"]["one"],
        timestamp=ts, tags=tags, host=host_id
    )
    stats.add(instance_id,
        'load.5', message["loadAverageMinute"]["five"],
        timestamp=ts, tags=tags, host=host_id
    )
    stats.add(instance_id,
        'load.15', message["loadAverageMinute"]["fifteen"],
        timestamp=ts, tags=tags, host=host_id
    )

    for namespace in ["cpuUtilization", "memory", "tasks", "swap"]:
        for key, value in message[namespace].iteritems():
            stats.add(instance_id,
                '%s.%s' % (namespace.lower(), key), value,
                timestamp=ts, tags=tags, host=host_id
            )

    for network_stats in message["network"]:
        network_interface = network_stats.pop("interface")
        network_tag = ["interface:%s" % network_interface]
        for key, value in network_stats.iteritems():
            stats.add(instance_id,
                'network.%s.%s' %(network_interface, key), value,
                timestamp=ts, tags=tags + network_tag, host=host_id
            )

    for disk_stats in message["diskIO"]:
        disk_device = disk_stats.pop("device")
        disk_tag = ["device:%s" % disk_device]
        for key, value in disk_stats.iteritems():
            stats.add(instance_id,
                'diskio.%s.%s' %(disk_device, key), value,
                timestamp=ts, tags=tags + disk_tag, host=host_id
            )

    for fs_stats in message["fileSys"]:
        fs_name = fs_stats.pop("name")
        fs_mountpoint = fs_stats.pop("mountPoint")
        fs_tag = [
            "name:%s" % fs_name,
            "mountPoint:%s" % fs_mountpoint
        ]
        for key, value in fs_stats.iteritems():
            stats.add(instance_id,
                'filesystem.%s.%s' %(fs_name,key), value,
                timestamp=ts, tags=tags + fs_tag, host=host_id
            )

    for process_stats in message["processList"]:
        process_name = process_stats.pop("name")
        process_id = process_stats.pop("id")
        process_tag = [
            "name:%s" % process_name,
            "id:%s" % process_id
        ]
        # This will end up creating a ton of metrics in Graphite, as process IDs are constantly changing.
        # TODO: Figure out a way to deal with this.. I'm thinking of just combining the process names that are the same
        # together, and including a process count with that. Otherwise, just forget it, and if you need detailed process
        # stats, use the AWS-provided dashboard?
        for key, value in process_stats.iteritems():
            # For now, require a match to "OS processes" or "RDS processes" to only match those two..
            if re.match(r"(OS|RDS) processes", process_name):
                stats.add(instance_id,
                    'process.%s.%s' %(process_name, key), value,
                    timestamp=ts, tags=tags + process_tag, host=host_id
                )
            #else:

def lambda_handler(event, context):
    ''' Process a RDS enhenced monitoring DATA_MESSAGE,
        coming from CLOUDWATCH LOGS
    '''
    # event is a dict containing a base64 string gzipped
    #print "Incoming event: " + json.dumps(event)
 
    event = event['awslogs']['data']
    event = json.loads(
        gzip.GzipFile(fileobj=StringIO(event.decode('base64'))).read()
    )

    #print "Decoded event: " + json.dumps(event)
    
    account = event['owner']
    region = context.invoked_function_arn.split(':', 4)[3]

    log_events = event['logEvents']

    # Store process events here, to combine and send later.
    combined_events = []

    for log_event in log_events:
        # The actual log events are escaped json - so we need to load that as json separately from the main load above.
        message = json.loads(log_event['message'])
        ts = log_event['timestamp'] / 1000
        _process_rds_enhanced_monitoring_message(ts, message, account, region, combined_events)

    stats.sendmetrics()

    return {'Status': 'OK'}


class Stats(object):

    def __init__(self):
        self.allmetrics = []

    def add(self, instance_id, metric, value, timestamp=None, tags=None, host=None):
        metricname = instance_id + '.' + metric
       
        # Ensure that the value can be converted to float; if not, proceed without error..
        try:
            float(value)
            metrics = (metricname, value, timestamp)
            self.allmetrics.append(metrics)
        except ValueError:
           pass

    def sendmetrics(self):
        allmetrics = self.allmetrics
        # Clear out for the next run..
        self.allmetrics = []

        # Connect to Graphite
        lambdalogger.info('Connecting to Graphite..')
        graphite = graphitesend.init(graphite_server=CARBON_SERVER,system_name='',prefix=CARBON_NAMESPACE,clean_metric_name=False)
        # If you want to test without sending any actual data, use this (dryrun=True)..
        #graphite = graphitesend.init(graphite_server=CARBON_SERVER,system_name='',prefix=CARBON_NAMESPACE,dryrun=True,clean_metric_name=False)

        # Bulk send all of our metrics to Graphite
        results = graphite.send_list(allmetrics)
        lambdalogger.debug(results)

        # Reset Graphite connection
        graphitesend.reset()

stats = Stats()

